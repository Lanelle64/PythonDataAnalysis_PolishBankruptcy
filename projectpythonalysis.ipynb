{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TnPu34h-apzJ"
      },
      "outputs": [],
      "source": [
        "from pylab import*\n",
        "import pandas as pd\n",
        "from scipy.io import arff\n",
        "import plotly.express as px\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.DataFrame(arff.loadarff('1year.arff')[0])\n",
        "df2 = pd.DataFrame(arff.loadarff('2year.arff')[0])\n",
        "df3 = pd.DataFrame(arff.loadarff('3year.arff')[0])\n",
        "df4 = pd.DataFrame(arff.loadarff('4year.arff')[0])\n",
        "df5 = pd.DataFrame(arff.loadarff('5year.arff')[0])"
      ],
      "metadata": {
        "id": "59BVObRLa8eN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "45d80dcd-b8e1-46ff-b206-4c81c1388698"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-11d9fca01107>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadarff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1year.arff'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadarff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2year.arff'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadarff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'3year.arff'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadarff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'4year.arff'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadarff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'5year.arff'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/io/arff/_arffread.py\u001b[0m in \u001b[0;36mloadarff\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0mofile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m         \u001b[0mofile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_loadarff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mofile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1year.arff'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns=[\n",
        "\"net profit / total assets\"\n",
        ",\"total liabilities / total assets\"\n",
        ",\"working capital / total assets\"\n",
        ",\"current assets / short-term liabilities\"\n",
        ",\"[(cash + short-term securities + receivables - short-term liabilities) / (operating expenses - depreciation)] * 365\"\n",
        ",\"retained earnings / total assets\"\n",
        ",\"EBIT / total assets\"\n",
        ",\"book value of equity / total liabilities\"\n",
        ",\"sales / total assets\"\n",
        ",\"equity / total assets\"\n",
        ",\"(gross profit + extraordinary items + financial expenses) / total assets\"\n",
        ",\"gross profit / short-term liabilities\"\n",
        ",\"(gross profit + depreciation) / sales\"\n",
        ",\"(gross profit + interest) / total assets\"\n",
        ",\"(total liabilities * 365) / (gross profit + depreciation)\"\n",
        ",\"(gross profit + depreciation) / total liabilities\"\n",
        ",\"total assets / total liabilities\"\n",
        ",\"gross profit / total assets\"\n",
        ",\"gross profit / sales\"\n",
        ",\"(inventory * 365) / sales\"\n",
        ",\"sales (n) / sales (n-1)\"\n",
        ",\"profit on operating activities / total assets\"\n",
        ",\"net profit / sales\"\n",
        ",\"gross profit (in 3 years) / total assets\"\n",
        ",\"(equity - share capital) / total assets\"\n",
        ",\"(net profit + depreciation) / total liabilities\"\n",
        ",\"profit on operating activities / financial expenses\"\n",
        ",\"working capital / fixed assets\"\n",
        ",\"logarithm of total assets\"\n",
        ",\"(total liabilities - cash) / sales\"\n",
        ",\"(gross profit + interest) / sales\"\n",
        ",\"(current liabilities * 365) / cost of products sold\"\n",
        ",\"operating expenses / short-term liabilities\"\n",
        ",\"operating expenses / total liabilities\"\n",
        ",\"profit on sales / total assets\"\n",
        ",\"total sales / total assets\"\n",
        ",\"(current assets - inventories) / long-term liabilities\"\n",
        ",\"constant capital / total assets\"\n",
        ",\"profit on sales / sales\"\n",
        ",\"(current assets - inventory - receivables) / short-term liabilities\"\n",
        ",\"total liabilities / ((profit on operating activities + depreciation) * (12/365))\"\n",
        ",\"profit on operating activities / sales\"\n",
        ",\"rotation receivables + inventory turnover in days\"\n",
        ",\"(receivables * 365) / sales\"\n",
        ",\"net profit / inventory\"\n",
        ",\"(current assets - inventory) / short-term liabilities\"\n",
        ",\"(inventory * 365) / cost of products sold\"\n",
        ",\"EBITDA (profit on operating activities - depreciation) / total assets\"\n",
        ",\"EBITDA (profit on operating activities - depreciation) / sales\"\n",
        ",\"current assets / total liabilities\"\n",
        ",\"short-term liabilities / total assets\"\n",
        ",\"(short-term liabilities * 365) / cost of products sold)\"\n",
        ",\"equity / fixed assets\"\n",
        ",\"constant capital / fixed assets\"\n",
        ",\"working capital\"\n",
        ",\"(sales - cost of products sold) / sales\"\n",
        ",\"(current assets - inventory - short-term liabilities) / (sales - gross profit - depreciation)\"\n",
        ",\"total costs /total sales\"\n",
        ",\"long-term liabilities / equity\"\n",
        ",\"sales / inventory\"\n",
        ",\"sales / receivables\"\n",
        ",\"(short-term liabilities *365) / sales\"\n",
        ",\"sales / short-term liabilities\"\n",
        ",\"sales / fixed assets\",\"a predire\"]"
      ],
      "metadata": {
        "id": "hr4YNUE6Eb5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.columns=columns\n",
        "df2.columns=columns\n",
        "df3.columns=columns\n",
        "df4.columns=columns\n",
        "df5.columns=columns"
      ],
      "metadata": {
        "id": "_e8rQzOfeN_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.info"
      ],
      "metadata": {
        "id": "mBiBgRkXef4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.isnull().sum()"
      ],
      "metadata": {
        "id": "uLru1d4aemny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.isnull().sum().sort_values()"
      ],
      "metadata": {
        "id": "PywHV5XAe2zA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.describe()"
      ],
      "metadata": {
        "id": "is1inD0-ZOwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def switch(x):\n",
        "  if b'0' == x:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1"
      ],
      "metadata": {
        "id": "KzBTxFbBABzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['a predire']=df1['a predire'].transform(switch)\n",
        "df2['a predire']=df2['a predire'].transform(switch)\n",
        "df3['a predire']=df3['a predire'].transform(switch)\n",
        "df4['a predire']=df4['a predire'].transform(switch)\n",
        "df5['a predire']=df5['a predire'].transform(switch)\n",
        "df1['a predire']"
      ],
      "metadata": {
        "id": "B7a-1uX29jQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1corr=df1.copy()\n",
        "df1corr.dropna(axis=0,inplace=True)\n",
        "corr = df1corr.corr()\n",
        "ax = sns.heatmap(corr)\n",
        "ax"
      ],
      "metadata": {
        "id": "odAvTZtEh855"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.hist(figsize=(80,60))"
      ],
      "metadata": {
        "id": "ZhIBGp21jRwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['a predire'].hist()"
      ],
      "metadata": {
        "id": "RhhTjne_j2sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "# You must normalize the data before applying the fit method\n",
        "pcadf1=df1.copy()\n",
        "pcadf1.drop(columns='a predire',inplace=True)\n",
        "pcadf1.dropna(axis=0,inplace=True)\n",
        "df1_normalized=(pcadf1 - pcadf1.mean()) / pcadf1.std()\n",
        "#df1_normalized.dropna(axis=1,inplace=True)\n",
        "pca = PCA(n_components=pcadf1.shape[1])\n",
        "pca.fit(df1_normalized)\n",
        "# Reformat and view results\n",
        "loadings = pd.DataFrame(pca.components_.T,\n",
        "columns=['PC%s' % _ for _ in range(len(df1_normalized.columns))],\n",
        "index=pcadf1.columns)\n",
        "print(loadings)\n",
        "plot(pca.explained_variance_ratio_)\n",
        "ylabel('Explained Variance')\n",
        "xlabel('Components')\n",
        "grid()\n",
        "show()\n",
        "print(pca.explained_variance_ratio_)"
      ],
      "metadata": {
        "id": "g4cffEkwlj__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pexpdata(l,p):\n",
        "  for i in range(len(l)):\n",
        "    if l[i]>p:\n",
        "      return i"
      ],
      "metadata": {
        "id": "aMFQqy4esOZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comp=pca.explained_variance_ratio_\n",
        "cum_ex_var_r=[comp[:i].sum() for i in range(len(comp))]\n",
        "plot(cum_ex_var_r)\n",
        "ylabel('cumulative Explained Variance')\n",
        "xlabel('Components')\n",
        "grid()\n",
        "show()\n",
        "print(cum_ex_var_r[44])"
      ],
      "metadata": {
        "id": "MNmbkKE9kyfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduc=pca.components_[:pexpdata(cum_ex_var_r,0.99)]\n",
        "reddf1=df1.copy()\n",
        "reddf1.dropna(axis=0,inplace=True)\n",
        "apredire=reddf1['a predire']\n",
        "reddf1.drop(columns='a predire',inplace=True)\n",
        "reddf1=reddf1.dot(reduc.T)\n",
        "reddf1['a predire']=apredire\n",
        "reddf1"
      ],
      "metadata": {
        "id": "0eVfCdXyP2f3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reddf1['a predire'].value_counts(0)"
      ],
      "metadata": {
        "id": "FFr7Sq1pZov7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = reddf1.loc[:, reddf1.columns != \"a predire\"]\n",
        "y = apredire\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=20)"
      ],
      "metadata": {
        "id": "DKzQ8-LFeejo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestCentroid\n",
        "clf=NearestCentroid()\n",
        "clf.fit(X_train, y_train)\n",
        "pred=clf.predict(X_test)\n",
        "acc=1-array([abs(list(y_test)[i]-pred[i]) for i in range(len(pred))]).sum()/len(pred)\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "-ssUS0kZgrWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pcadf1=df2.copy()\n",
        "pcadf1.drop(columns='a predire',inplace=True)\n",
        "pcadf1.dropna(axis=0,inplace=True)\n",
        "df1_normalized=(pcadf1 - pcadf1.mean()) / pcadf1.std()\n",
        "#df1_normalized.dropna(axis=1,inplace=True)\n",
        "pca = PCA(n_components=pcadf1.shape[1])\n",
        "pca.fit(df1_normalized)\n",
        "# Reformat and view results\n",
        "loadings = pd.DataFrame(pca.components_.T,\n",
        "columns=['PC%s' % _ for _ in range(len(df1_normalized.columns))],\n",
        "index=pcadf1.columns)\n",
        "comp=pca.explained_variance_ratio_\n",
        "cum_ex_var_r=[comp[:i].sum() for i in range(len(comp))]\n",
        "reduc=pca.components_[:pexpdata(cum_ex_var_r,0.99)]\n",
        "reddf1=df2.copy()\n",
        "reddf1.dropna(axis=0,inplace=True)\n",
        "apredire=reddf1['a predire']\n",
        "reddf1.drop(columns='a predire',inplace=True)\n",
        "reddf1=reddf1.dot(reduc.T)\n",
        "reddf1['a predire']=apredire\n",
        "X = reddf1.loc[:, reddf1.columns != \"a predire\"]\n",
        "y = apredire\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=20)\n",
        "clf=NearestCentroid()\n",
        "clf.fit(X_train, y_train)\n",
        "pred=clf.predict(X_test)\n",
        "acc=1-array([abs(list(y_test)[i]-pred[i]) for i in range(len(pred))]).sum()/len(pred)\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "kMbIFEb9rd5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pcadf1=df3.copy()\n",
        "pcadf1.drop(columns='a predire',inplace=True)\n",
        "pcadf1.dropna(axis=0,inplace=True)\n",
        "df1_normalized=(pcadf1 - pcadf1.mean()) / pcadf1.std()\n",
        "#df1_normalized.dropna(axis=1,inplace=True)\n",
        "pca = PCA(n_components=pcadf1.shape[1])\n",
        "pca.fit(df1_normalized)\n",
        "# Reformat and view results\n",
        "loadings = pd.DataFrame(pca.components_.T,\n",
        "columns=['PC%s' % _ for _ in range(len(df1_normalized.columns))],\n",
        "index=pcadf1.columns)\n",
        "comp=pca.explained_variance_ratio_\n",
        "cum_ex_var_r=[comp[:i].sum() for i in range(len(comp))]\n",
        "reduc=pca.components_[:pexpdata(cum_ex_var_r,0.99)]\n",
        "reddf1=df3.copy()\n",
        "reddf1.dropna(axis=0,inplace=True)\n",
        "apredire=reddf1['a predire']\n",
        "reddf1.drop(columns='a predire',inplace=True)\n",
        "reddf1=reddf1.dot(reduc.T)\n",
        "reddf1['a predire']=apredire\n",
        "X = reddf1.loc[:, reddf1.columns != \"a predire\"]\n",
        "y = apredire\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=20)\n",
        "clf=NearestCentroid()\n",
        "clf.fit(X_train, y_train)\n",
        "pred=clf.predict(X_test)\n",
        "acc=1-array([abs(list(y_test)[i]-pred[i]) for i in range(len(pred))]).sum()/len(pred)\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "asDyYKm5uGpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pcadf1=df4.copy()\n",
        "pcadf1.drop(columns='a predire',inplace=True)\n",
        "pcadf1.dropna(axis=0,inplace=True)\n",
        "df1_normalized=(pcadf1 - pcadf1.mean()) / pcadf1.std()\n",
        "#df1_normalized.dropna(axis=1,inplace=True)\n",
        "pca = PCA(n_components=pcadf1.shape[1])\n",
        "pca.fit(df1_normalized)\n",
        "# Reformat and view results\n",
        "loadings = pd.DataFrame(pca.components_.T,\n",
        "columns=['PC%s' % _ for _ in range(len(df1_normalized.columns))],\n",
        "index=pcadf1.columns)\n",
        "comp=pca.explained_variance_ratio_\n",
        "cum_ex_var_r=[comp[:i].sum() for i in range(len(comp))]\n",
        "reduc=pca.components_[:pexpdata(cum_ex_var_r,0.99)]\n",
        "reddf1=df4.copy()\n",
        "reddf1.dropna(axis=0,inplace=True)\n",
        "apredire=reddf1['a predire']\n",
        "reddf1.drop(columns='a predire',inplace=True)\n",
        "reddf1=reddf1.dot(reduc.T)\n",
        "reddf1['a predire']=apredire\n",
        "X = reddf1.loc[:, reddf1.columns != \"a predire\"]\n",
        "y = apredire\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=20)\n",
        "clf=NearestCentroid()\n",
        "clf.fit(X_train, y_train)\n",
        "pred=clf.predict(X_test)\n",
        "acc=1-array([abs(list(y_test)[i]-pred[i]) for i in range(len(pred))]).sum()/len(pred)\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "MNNMD1bkubai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pcadf1=df5.copy()\n",
        "pcadf1.drop(columns='a predire',inplace=True)\n",
        "pcadf1.dropna(axis=0,inplace=True)\n",
        "df1_normalized=(pcadf1 - pcadf1.mean()) / pcadf1.std()\n",
        "#df1_normalized.dropna(axis=1,inplace=True)\n",
        "pca = PCA(n_components=pcadf1.shape[1])\n",
        "pca.fit(df1_normalized)\n",
        "# Reformat and view results\n",
        "loadings = pd.DataFrame(pca.components_.T,\n",
        "columns=['PC%s' % _ for _ in range(len(df1_normalized.columns))],\n",
        "index=pcadf1.columns)\n",
        "comp=pca.explained_variance_ratio_\n",
        "cum_ex_var_r=[comp[:i].sum() for i in range(len(comp))]\n",
        "reduc=pca.components_[:pexpdata(cum_ex_var_r,0.99)]\n",
        "reddf1=df5.copy()\n",
        "reddf1.dropna(axis=0,inplace=True)\n",
        "apredire=reddf1['a predire']\n",
        "reddf1.drop(columns='a predire',inplace=True)\n",
        "reddf1=reddf1.dot(reduc.T)\n",
        "reddf1['a predire']=apredire\n",
        "X = reddf1.loc[:, reddf1.columns != \"a predire\"]\n",
        "y = apredire\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=20)\n",
        "clf=NearestCentroid()\n",
        "clf.fit(X_train, y_train)\n",
        "pred=clf.predict(X_test)\n",
        "acc=1-array([abs(list(y_test)[i]-pred[i]) for i in range(len(pred))]).sum()/len(pred)\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "dFTs9swbum3h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}